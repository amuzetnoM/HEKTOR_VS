# Vector Studio v2.3.0 - Quick Start API Reference

**5-Minute Guide to Distributed Infrastructure and ML Integration**

---

## Installation

```bash
# Clone and build
git clone https://github.com/amuzetnoM/vector_studio.git
cd vector_studio && mkdir build && cd build

cmake -DCMAKE_BUILD_TYPE=Release \
      -DVDB_USE_TENSORFLOW=ON \
      -DVDB_USE_TORCH=ON \
      -DVDB_ENABLE_DISTRIBUTED=ON \
      -DCMAKE_TOOLCHAIN_FILE=/path/to/vcpkg/scripts/buildsystems/vcpkg.cmake \
      ..

cmake --build . --parallel 8
sudo cmake --install .
```

---

## 1. Basic Distributed Database

```cpp
#include "vdb/distributed_database.hpp"

// Setup replication (2 nodes, async)
ReplicationConfig repl_config;
repl_config.mode = ReplicationMode::Async;

NodeConfig node1{"node1", "localhost", 8080, true, 10};
repl_config.nodes.push_back(node1);

// Setup sharding (2 shards, hash-based)
ShardingConfig shard_config;
shard_config.strategy = ShardingStrategy::Hash;
shard_config.num_shards = 2;

ShardConfig shard0{"shard0", "localhost", 9000};
ShardConfig shard1{"shard1", "localhost", 9001};
shard_config.shards = {shard0, shard1};

// Create database
DistributedVectorDatabase db(repl_config, shard_config);
db.init(768, DistanceMetric::Cosine);  // BERT dimension

// Add vector
Vector vec(768);
// ... populate vec ...
Metadata meta{.id = 1, .source_file = "doc.txt"};
auto id = db.add(vec.view(), meta);

// Search
auto results = db.search(vec.view(), 10);
for (const auto& r : results.value()) {
    std::cout << "ID: " << r.id << ", Score: " << r.score << "\n";
}

db.close();
```

---

## 2. TensorFlow Embedding

```cpp
#include "vdb/framework_integration.hpp"

// Load TensorFlow model
TensorFlowConfig tf_config;
tf_config.model_path = "/models/bert-base";
tf_config.use_gpu = true;

TensorFlowEmbedder embedder(tf_config);

// Embed text
auto result = embedder.embed("Hello, world!");
if (result) {
    Vector embedding = result.value();  // L2-normalized
    std::cout << "Dimension: " << embedding.size() << "\n";
}

// Batch embedding
std::vector<std::string> texts = {"Text 1", "Text 2", "Text 3"};
auto batch = embedder.embed_batch(texts);
```

---

## 3. PyTorch Embedding

```cpp
#include "vdb/framework_integration.hpp"

// Load PyTorch model
PyTorchConfig pt_config;
pt_config.model_path = "/models/sbert.pt";
pt_config.device = "cuda";  // or "cpu"
pt_config.use_half_precision = true;  // FP16 for GPU

PyTorchEmbedder embedder(pt_config);

// Embed text
auto result = embedder.embed("Sample text");
if (result) {
    Vector embedding = result.value();
}

// Check device
std::cout << "Running on: " << embedder.device() << "\n";
```

---

## 4. Complete Pipeline (TensorFlow + Distributed DB)

```cpp
#include "vdb/framework_integration.hpp"
#include "vdb/distributed_database.hpp"

int main() {
    // Setup embedder
    TensorFlowConfig tf_config{
        .model_path = "/models/bert",
        .use_gpu = true
    };
    TensorFlowEmbedder embedder(tf_config);
    
    // Setup distributed DB
    ReplicationConfig repl;
    repl.mode = ReplicationMode::SemiSync;
    repl.min_replicas = 2;
    // ... add nodes ...
    
    ShardingConfig shard;
    shard.strategy = ShardingStrategy::ConsistentHash;
    shard.num_shards = 4;
    // ... add shards ...
    
    DistributedVectorDatabase db(repl, shard);
    db.init(embedder.dimension(), DistanceMetric::Cosine);
    
    // Store documents
    std::vector<std::string> docs = {
        "Machine learning is powerful",
        "Deep learning transforms AI",
        "Vector databases enable search"
    };
    
    for (size_t i = 0; i < docs.size(); ++i) {
        auto embed = embedder.embed(docs[i]);
        if (embed) {
            Metadata meta{.id = i};
            db.add(embed.value().view(), meta);
        }
    }
    
    // Search
    std::string query = "What is machine learning?";
    auto query_embed = embedder.embed(query);
    
    if (query_embed) {
        auto results = db.search(query_embed.value().view(), 3);
        if (results) {
            for (const auto& r : results.value()) {
                std::cout << "Found: " << docs[r.id] 
                          << " (score: " << r.score << ")\n";
            }
        }
    }
    
    db.close();
    return 0;
}
```

---

## 5. Replication Modes

```cpp
// ASYNC: Fire-and-forget, minimal latency
config.mode = ReplicationMode::Async;

// SYNC: Wait for all replicas, strong consistency
config.mode = ReplicationMode::Sync;
config.sync_timeout_ms = 5000;

// SEMI-SYNC: Wait for quorum, balanced
config.mode = ReplicationMode::SemiSync;
config.min_replicas = 2;  // Primary + 1 replica
```

---

## 6. Sharding Strategies

```cpp
// HASH: Uniform distribution
config.strategy = ShardingStrategy::Hash;

// RANGE: Ordered keys
config.strategy = ShardingStrategy::Range;
shard0.start_range = 0;
shard0.end_range = 1000000;

// CONSISTENT HASH: Minimal data movement
config.strategy = ShardingStrategy::ConsistentHash;
config.virtual_nodes_per_shard = 150;
```

---

## 7. Health Monitoring

```cpp
// Check cluster health
auto health = db.is_cluster_healthy();
if (health && health.value()) {
    std::cout << "Cluster is healthy\n";
}

// Get cluster stats
auto stats = db.get_cluster_stats();
if (stats) {
    std::cout << "Total vectors: " << stats->total_vectors << "\n";
    std::cout << "Shards: " << stats->num_shards << "\n";
}

// Check replication status
auto primary = repl_mgr.get_primary_node();
std::cout << "Primary: " << primary.value() << "\n";
```

---

## 8. Training Data Export

```cpp
// TensorFlow export (TFRecord format)
std::vector<Vector> vectors;
std::vector<std::string> labels;
// ... populate data ...

embedder.export_for_training(vectors, labels, "/data/train.tfrecord");

// PyTorch export (tensor format)
embedder.export_for_training(vectors, labels, "/data/train");
// Creates: train.pt and train.labels
```

---

## 9. Error Handling

```cpp
auto result = db.add(vec.view(), meta);
if (!result) {
    std::cerr << "Error: " << result.error().message() << "\n";
    std::cerr << "Code: " << result.error().code() << "\n";
}

// Or with value check
if (result) {
    VectorId id = result.value();
    std::cout << "Added with ID: " << id << "\n";
}
```

---

## 10. Concurrent Operations

```cpp
#include <thread>
#include <vector>

std::vector<std::thread> threads;
std::atomic<int> count{0};

for (int t = 0; t < 4; ++t) {
    threads.emplace_back([&]() {
        for (int i = 0; i < 100; ++i) {
            // Thread-safe operations
            auto embed = embedder.embed("Text " + std::to_string(i));
            if (embed) {
                Metadata meta{.id = t * 100 + i};
                if (db.add(embed.value().view(), meta)) {
                    count++;
                }
            }
        }
    });
}

for (auto& t : threads) t.join();
std::cout << "Added " << count.load() << " vectors\n";
```

---

## Configuration Reference

### Replication Config
```cpp
struct ReplicationConfig {
    ReplicationMode mode = Async;
    int min_replicas = 1;              // For semi-sync
    int heartbeat_interval_ms = 1000;  // Health check interval
    int sync_timeout_ms = 5000;        // Sync operation timeout
    std::vector<NodeConfig> nodes;
};
```

### Sharding Config
```cpp
struct ShardingConfig {
    ShardingStrategy strategy = Hash;
    int num_shards = 1;
    int virtual_nodes_per_shard = 150;    // For consistent hash
    uint64_t resharding_threshold = 1000000;
    float imbalance_threshold = 0.25f;
    std::vector<ShardConfig> shards;
};
```

### TensorFlow Config
```cpp
struct TensorFlowConfig {
    std::string model_path;
    bool use_gpu = false;
    float gpu_memory_fraction = 1.0f;
    int num_threads = 0;  // 0 = auto
    std::string input_tensor_name = "input";
    std::string output_tensor_name = "output";
};
```

### PyTorch Config
```cpp
struct PyTorchConfig {
    std::string model_path;
    std::string device = "cpu";  // "cpu", "cuda", "cuda:0"
    int num_threads = 0;
    bool use_half_precision = false;  // FP16 on GPU
};
```

---

## Performance Tips

1. **Async replication** for write-heavy workloads
2. **Consistent hashing** for dynamic cluster resizing
3. **Batch embedding** for better GPU utilization
4. **Half precision (FP16)** for 2x faster GPU inference
5. **Pre-warm models** during startup
6. **Monitor imbalance** and reshard when needed
7. **Use filters** to reduce search space
8. **Scale shards horizontally** for large datasets

---

## Testing

```bash
# Build with tests
cmake -DVDB_BUILD_TESTS=ON ..
cmake --build .

# Run all tests
ctest --output-on-failure

# Run specific test suite
./tests/test_distributed
./tests/test_ml_frameworks
./tests/test_end_to_end
```

---

## Full Documentation

See [V2.3.0_DISTRIBUTED_ML_GUIDE.md](V2.3.0_DISTRIBUTED_ML_GUIDE.md) for comprehensive documentation including:
- Complete architecture diagrams
- Detailed API reference
- Performance benchmarks
- Troubleshooting guide
- Production deployment guide

---

## Support

- **Docs**: https://vector-studio.readthedocs.io
- **Issues**: https://github.com/amuzetnoM/vector_studio/issues
- **Discord**: https://discord.gg/vector-studio

---

**Vector Studio v2.3.0** - Production-Ready Distributed Vector Database with ML Framework Integration
